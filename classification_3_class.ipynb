{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,shutil,math,scipy,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import Image as pil_image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from time import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from IPython.display import SVG\n",
    "\n",
    "from scipy import misc,ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Sequential,Input,Model\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split_folders in /home/akshaya/.pyenv/versions/3.7.6/envs/tf2137/lib/python3.7/site-packages (0.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install library for spliting data\n",
    "!pip install split_folders\n",
    "import split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './classification_data/'\n",
    "split_folder = './classification_split_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./classification_split_data/ already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(split_folder)==False:\n",
    "    os.mkdir(split_folder)\n",
    "else:\n",
    "    print('{} already exists'.format(split_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 869 files [00:00, 4360.66 files/s]\n"
     ]
    }
   ],
   "source": [
    "# split the data in ratio train 80%, test 10%, validation 10%\n",
    "split_data = True\n",
    "if split_data == True:\n",
    "    split_folders.ratio(img_dir, output= split_folder, seed=1337, ratio=(.8, .1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./classification_split_data/train ./classification_split_data/test ./classification_split_data/val\n"
     ]
    }
   ],
   "source": [
    "x_train_dir = os.path.join(split_folder, 'train')\n",
    "x_test_dir = os.path.join(split_folder, 'test')\n",
    "x_val_dir = os.path.join(split_folder, 'val')\n",
    "\n",
    "print(x_train_dir, x_test_dir, x_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_final_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 images belonging to 3 classes.\n",
      "Found 85 images belonging to 3 classes.\n",
      "Found 90 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "imgsize = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=10,rescale=1/255,fill_mode=\"nearest\")\n",
    "valid_datagen = ImageDataGenerator(rotation_range=10,rescale=1/255,fill_mode=\"nearest\") \n",
    "test_datagen = ImageDataGenerator(rotation_range=10,rescale=1/255,fill_mode=\"nearest\") \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=x_train_dir,\n",
    "    target_size=(imgsize, imgsize),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=x_val_dir,\n",
    "    target_size=(imgsize,imgsize),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=x_test_dir,\n",
    "    target_size=(imgsize,imgsize),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6d75f54100> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6ccbe49f70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cc03d44f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc03d4eb0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cc0158f70> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6cc0149190> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc03a2430> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cc00bb850> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cc00a9e20> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc00d2df0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cc00e1190> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc0079ee0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cc00873d0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6cc007f610> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6cc007f490> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc0027850> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cc0027d30> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cc002b3a0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc0049310> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cc005c2e0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cc0050730> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac1333a0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6cac130370> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac14f730> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac14fc10> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cac154280> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac0f4f70> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6cac105220> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cac1001f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac0a1400> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac0ad7c0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6cac0a1e50> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6cac0a1d90> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac0c6b20> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac059580> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cac0d3880> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac076820> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cac076dc0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac01c880> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac01ce50> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6cac0222b0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6cac042970> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6cac053460> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6cac0504f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c70096700> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c700a0a90> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c70096d00> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c700bbdf0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c7004c0a0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c700436d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c700432b0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c700728e0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c70069910> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c487c8ee0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c487d53d0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c487cf610> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c487ede80> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c487804c0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6c4877c7c0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c487f7a30> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4879de80> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c487b0280> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c487a9250> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4874c550> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c487558e0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4876f5b0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c486f9970> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c4876fbe0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48714d30> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48727190> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c4871b850> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c486c33d0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c486cd790> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c486c3e20> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c486e8d00> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c486e89a0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c486f7d60> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4868ee80> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c486a2580> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c4869aa30> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4863b7f0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c4863bd90> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c486421f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48663eb0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48675160> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c48669790> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c486104f0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c4861a970> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c486109d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48636550> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c485c42b0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c485bd5e0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c485dcf10> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c485ee550> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c485eaa00> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4858b8e0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c4858bdc0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c48596040> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c485aeb50> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c48540370> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c485b57c0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48564400> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c485623d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48502790> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48502c70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c485082e0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48528f70> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c484b9220> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c485351f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c484d4400> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c484e27f0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c484d4e50> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4847abb0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c4847a520> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c484870a0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c484a0e50> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c484b6610> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c484a9ca0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4844f820> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c4844fdc0> True\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6c48455220> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c484550d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c483fd4f0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48407970> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c483fd9d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48422550> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c4842e460> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c483c7c70> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c483d44f0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c483ce670> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c483ce160> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48381820> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c483f6f40> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4839bdc0> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c483a9e20> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c483a3490> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48344c40> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48353400> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c483503d0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48370790> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c48370c70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c483762e0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c48315f70> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x7f6c48326220> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c483241f0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c482c1400> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c482ce7c0> True\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f6c482c1e50> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c482e7bb0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c482e7520> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c482f64c0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4828fe50> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6c482a3610> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6c4828fbb0> True\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f6c482466a0> True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,422,339\n",
      "Trainable params: 2,388,227\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(include_top=False,\n",
    "                  input_shape = (imgsize,imgsize,3),\n",
    "                  weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for layer in base_model.layers:\n",
    "    print(layer,layer.trainable)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'mobileNetV2Model_224',\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    save_weights_only=False\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.01,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    verbose=1, \n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint,earlystop, reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-de99cc305bee>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.3308\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28125, saving model to mobileNetV2Model_224\n",
      "WARNING:tensorflow:From /home/akshaya/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.1852 - accuracy: 0.3308 - val_loss: 0.2640 - val_accuracy: 0.2812 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.3943\n",
      "Epoch 00002: val_accuracy improved from 0.28125 to 0.35938, saving model to mobileNetV2Model_224\n",
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n",
      "21/21 [==============================] - 32s 2s/step - loss: 0.1557 - accuracy: 0.3943 - val_loss: 0.1539 - val_accuracy: 0.3594 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.4622\n",
      "Epoch 00003: val_accuracy improved from 0.35938 to 0.56250, saving model to mobileNetV2Model_224\n",
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n",
      "21/21 [==============================] - 32s 2s/step - loss: 0.1407 - accuracy: 0.4622 - val_loss: 0.1508 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.5680\n",
      "Epoch 00004: val_accuracy improved from 0.56250 to 0.60938, saving model to mobileNetV2Model_224\n",
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n",
      "21/21 [==============================] - 33s 2s/step - loss: 0.1008 - accuracy: 0.5680 - val_loss: 0.0821 - val_accuracy: 0.6094 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.6828\n",
      "Epoch 00005: val_accuracy did not improve from 0.60938\n",
      "21/21 [==============================] - 9s 412ms/step - loss: 0.0674 - accuracy: 0.6828 - val_loss: 0.1008 - val_accuracy: 0.6094 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.6858\n",
      "Epoch 00006: val_accuracy did not improve from 0.60938\n",
      "21/21 [==============================] - 7s 340ms/step - loss: 0.0645 - accuracy: 0.6858 - val_loss: 0.1003 - val_accuracy: 0.6094 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.7115\n",
      "Epoch 00007: val_accuracy improved from 0.60938 to 0.67188, saving model to mobileNetV2Model_224\n",
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "21/21 [==============================] - 24s 1s/step - loss: 0.0558 - accuracy: 0.7115 - val_loss: 0.0919 - val_accuracy: 0.6719 - lr: 1.0000e-04\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(lr=1e-4, momentum = 0.99)\n",
    "opt1 = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss=[focal_loss(alpha=.25, gamma=2)],\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n // batch_size,\n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobileNetV2Model_224/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, 'mobileNetV2Model_224', overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-0f79852df338>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "Confusion Matrix\n",
      "[[ 7  3 12]\n",
      " [ 3  5 14]\n",
      " [ 0  1 45]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      adding       0.70      0.32      0.44        22\n",
      "    stirring       0.56      0.23      0.32        22\n",
      "     unknown       0.63      0.98      0.77        46\n",
      "\n",
      "    accuracy                           0.63        90\n",
      "   macro avg       0.63      0.51      0.51        90\n",
      "weighted avg       0.63      0.63      0.58        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Saved\n"
     ]
    }
   ],
   "source": [
    "# Can be skipped. \n",
    "model_json = model.to_json()\n",
    "with open(\"mobileNetV2Model_224/MobileNetV2model_224.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save(\"mobileNetV2Model_224/MobileNetV2model_224.h5\")\n",
    "print(\"Weights Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_map = list(train_generator.class_indices.keys())\n",
    "with open('labels.txt', 'w') as outfile:\n",
    "    json.dump(label_map, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "frame = cv2.imread('./test_bkp/26.jpg')\n",
    "print(model.predict_classes(np.float32(np.reshape(cv2.resize(frame,(imgsize,imgsize)),(1,imgsize,imgsize,3)))/255.0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adding', 'stirring', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
